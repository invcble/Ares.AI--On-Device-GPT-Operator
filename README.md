# Ares.AI ğŸ“±âš¡

**Control your phone with one sentence. No taps. No scrolls. Just intent â†’ action.**

Ares.AI turns your high-level instructions like *"Open WhatsApp and message John"* into precise, automated mobile actions. Unlike traditional voice assistants that stop at simple tasks, Ares understands your screen and handles full workflowsâ€”like ordering a product or booking a rideâ€”with real-time UI interaction.

---

## ğŸ§  Inspiration

Siri and Google Assistant can set alarms or play musicâ€”but what if you want to complete multi-step tasks like:

- Booking an Uber
- Ordering your cart on Amazon
- Navigating settings and toggling modes

We asked: *Why does this still take dozens of taps?*  
**Ares.AI** was born from this frustrationâ€”to act like a smart human assistant with AI precision.

---

## ğŸš€ What It Does

- ğŸ” Understands high-level instructions like "Message Alex on Instagram"
- ğŸ§© Breaks it into step-by-step UI actions (tap, scroll, type, etc.)
- ğŸ‘ï¸ Analyzes your phone screen via screenshots
- ğŸ§  Maintains context of whatâ€™s done, whatâ€™s next, and what failed
- ğŸ”„ Retries, scrolls, adapts, or gives fallback instructions if stuck
- âœ… Executes real-time interactions with feedback loop

---

## âš™ï¸ Core Architecture

### ğŸ§­ Goal Planning with Gemini 2.5 Pro
- Input: `"Book Uber to airport"`
- Output: Sequence of structured **atomic actions** like:
  - Open app â†’ Tap search bar â†’ Type destination â†’ Tap "Book"

> Built using function calling with Gemini 2.5 Pro

### ğŸ§  Stateful Goal Execution
- Tracks progress per instruction
- Detects failure loops or stuck states
- Retries intelligently or attempts fallback actions

### ğŸ‘ï¸ Visual Grounding via Gemini Vision
- Screenshots are sent to Gemini Vision with contextual prompts
- Identifies the **correct bounding box** to tap/type/scroll
- Uses screenshot hashing to detect redundant frames
- Adapts if the element is missing (scroll, wait, retry)

---

## ğŸ§± Built With

- **Android Studio** â€” UI automation + screen capture
- **Kotlin** â€” Native Android agent logic
- **Python** â€” Server + reasoning loop
- **Gemini 2.5 Pro + Vision** â€” Planning and grounding
- **Figma** â€” UI prototyping

---

## ğŸš§ Challenges We Faced

- ğŸŒ€ **UI Inconsistency** â€” Varying app layouts required adaptive vision grounding
- âš¡ **Real-Time Performance** â€” Balancing model calls with latency
- ğŸ§­ **State Recovery** â€” Detecting dead-ends and designing recovery heuristics
- ğŸ§  **Natural Loop Avoidance** â€” Avoiding repeated steps when stuck

---

## ğŸ¤– Outcome

Ares.AI feels like a human assistant with:
- AI-level consistency
- Visual awareness
- Resilience in unknown app flows

> From intent â†’ screen understanding â†’ action execution  
> Ares closes the loop in mobile automation.

---

## ğŸ“ Roadmap (What's Next)

- ğŸ” Permission-aware automation (auto-detect required permissions)
- ğŸ§  Long-term memory for task continuity across sessions
- ğŸŒ Web interface for remote task triggering
- ğŸ“Š Logs & analytics for debugging agent behavior
- ğŸ¤ Community plugin system (custom atomic actions)

---
## ğŸ¥ Demo

[![Watch the demo](https://img.youtube.com/vi/awKfjunMDRg/0.jpg)](https://www.youtube.com/watch?v=awKfjunMDRg)

---

## ğŸ¤ Contributing

We welcome PRs, feature ideas, and collaborations!  
Please open an issue to start the conversation.

---

## ğŸ“œ License

MIT License

---

## ğŸ§  Shoutout

Inspired by the simplicity of real human assistants and powered by Googleâ€™s Gemini.  
*Ares doesnâ€™t ask howâ€”it just gets it done.*
